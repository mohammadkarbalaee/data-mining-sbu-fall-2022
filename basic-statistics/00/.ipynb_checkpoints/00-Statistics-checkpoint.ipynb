{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial imports\n",
    "We import associated libraries like pandas and numpy to load and interact with dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstemgraphic\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import stemgraphic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "We use diabetes dataset in this notebook. So the first step is to load the dataset using pandas library and pandas DataFrame data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../datasets/diabetes.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scales\n",
    "## Interval Scale\n",
    "If an scale that is a real number, preserves the ratio of every two difference, its called an Internal Scale.\n",
    "\n",
    "For example in below we can show that column S2 that shows ldl of each person by the unit of mg/dL , is a kind of interval scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval_scale_ratio(x1, x2, x3, x4):\n",
    "    return (x4 - x3) / (x2 - x1)\n",
    "\n",
    "x1, x2, x3, x4 = df[:4]['S2']\n",
    "print(\"The ratio in unit mg/dL is: \", get_interval_scale_ratio(x1, x2, x3, x4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we convert the unit from mg/dL to g/L in order to compare the ratio of new scale with previouse one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mgperdl_to_gperl(x):\n",
    "    return x * 0.01\n",
    "\n",
    "y1, y2, y3, y4 = [mgperdl_to_gperl(x) for x in [x1, x2, x3, x4]]\n",
    "print(\"The ratio in unit g/L is: \", get_interval_scale_ratio(y1, y2, y3, y4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio Scale\n",
    "If a real number scale, preserves the ratio, it is called Ratio Scale.\n",
    "We use x1 and x2 and also y1 and y2 to demonstrate that ldl is a kind of Ratio Scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The ratio of x1 and x2 is: \", x1/ x2)\n",
    "print(\"The ratio of y1 and y2 is: \", y1/ y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "There are two kinds of variables that is a feature of all data.\n",
    "1. Grouping Variables\n",
    "2. Quantitative Variables\n",
    "\n",
    "## Grouping Variables\n",
    "A grouping variable is a variable that is used to classify datas. It is measured by nominal or ordinal scales and classifies due to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby('SEX')\n",
    "print(\"SEX 1 group: \")\n",
    "print(grouped_data.get_group(1).head())\n",
    "print()\n",
    "print(\"SEX 2 group: \")\n",
    "print(grouped_data.get_group(2).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rounding continuous data \n",
    "Ù‹We can round datas of column S5 to two decimal places and also datas of column S2 to 0 decimal places at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round({'S5': 2, 'S2': 0}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency\n",
    "## Types of Frequency\n",
    "- Absolute Frequency\n",
    "- Relative Frequency\n",
    "- Cumulative Frequency\n",
    "- Cumulative Relative Frequency\n",
    "\n",
    "\n",
    "We can group S2 column (ldl) to 30 mg/dL width intervals. And then calculate each interval's frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_freq_df = df.copy()\n",
    "n = 30\n",
    "first = 70\n",
    "s2_freq_df[\"s2_ranges\"] = (s2_freq_df['S2']\n",
    "         .sub(first).floordiv(n)\n",
    "         .mul(n).add(first).map(lambda x: pd.Interval(x, x + 30))\n",
    "         )\n",
    "s2_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_frequencies = s2_freq_df[\"s2_ranges\"].value_counts().sort_index()\n",
    "absolute_frequencies.rename(\"f_i\", inplace=True)\n",
    "print(\"Absolute Frequencies are as below: \")\n",
    "print(absolute_frequencies)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_frequencies = s2_freq_df[\"s2_ranges\"].value_counts(normalize=True).sort_index()\n",
    "relative_frequencies.rename(\"r_i\", inplace=True)\n",
    "print(\"Relative Frequencies are as below: \")\n",
    "print(relative_frequencies)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_frequencies = absolute_frequencies.cumsum()\n",
    "cumulative_frequencies.rename(\"g_i\", inplace=True)\n",
    "print(\"Cumulative Frequencies are as below: \")\n",
    "print(cumulative_frequencies)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_relative_frequencies = relative_frequencies.cumsum()\n",
    "cumulative_relative_frequencies.rename(\"s_i\", inplace=True)\n",
    "print(\"Cumulative Relative Frequencies are as below: \")\n",
    "print(cumulative_relative_frequencies)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can merge 3 series into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_all_freq_df = pd.concat([absolute_frequencies, relative_frequencies, cumulative_frequencies, cumulative_relative_frequencies], axis=1)\n",
    "s2_all_freq_df[\"c_i\"] = s2_all_freq_df.index.map(lambda x: (x.left + x.right) / 2)\n",
    "s2_all_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_labels = [\"UNDERWEIGHT\", \"HEALTHY\", \"OVERWEIGT\", \"OBESE\"]\n",
    "df_bmi_grouped = df.copy()\n",
    "df_bmi_grouped[\"BMI_bins\"] = pd.cut(\n",
    "    df_bmi_grouped['BMI'], bins=[0, 18.5, 25, 30, 40], labels=bmi_labels)\n",
    "print(df_bmi_grouped)\n",
    "df_bmi_grouped = df_bmi_grouped.groupby([\"BMI_bins\"]).size().sort_values()\n",
    "df_bmi_grouped.plot.pie(y=\"BMI_bins\", startangle=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_all_freq_df.plot.bar(x='c_i', y='f_i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.box(column=[\"BP\"], vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s3_grouped = df.copy()\n",
    "df_s3_grouped[\"S3_bins\"] = pd.cut(df_s3_grouped[\"S3\"], bins=10)\n",
    "df_s3_grouped = df_s3_grouped.groupby([\"S3_bins\"]).size().cumsum()\n",
    "df_s3_grouped.plot.line(y=\"S3_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.plot.hist(column=[\"S2\"], bins=   np.arange(40, 251, 30))\n",
    "df.plot.hist(column=[\"S2\"], bins=np.arange(40, 251, 30), cumulative=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Diagram (+ Qumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([s2_all_freq_df.iloc[0]['c_i'] - 30, *s2_all_freq_df['c_i'], s2_all_freq_df.iloc[-1]['c_i'] + 30])\n",
    "y = np.array([0, *s2_all_freq_df['f_i'], 0])\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([s2_all_freq_df.iloc[0]['c_i'] - 30, *s2_all_freq_df['c_i'], s2_all_freq_df.iloc[-1]['c_i'] + 30])\n",
    "y = np.array([0, *s2_all_freq_df['g_i'], 0])\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Frequency Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "  \n",
    "x_axis = np.arange(-20, 20, 0.01)\n",
    "mean = 4\n",
    "std = 3\n",
    "  \n",
    "plt.plot(x_axis, norm.pdf(x_axis, mean, std))\n",
    "plt.show()\n",
    "plt.plot(x_axis, norm.cdf(x_axis, mean, std))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean (Arithmetic)\n",
    "We can simply find the mean of the data in a column by calling `mean` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_mean = df[\"S2\"].mean()\n",
    "print(\"The mean of column 'S2' is {} mg/dL\".format(df_s2_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can call mean method on whole dataframe to represent mean of every column in the table in a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean of each column are as below: \")\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Mean\n",
    "The pandas dataframe class itself does not provide a method to calculate geometric mean.\n",
    "\n",
    "So we get help from `scipy` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import gmean\n",
    "df_s2_gmean = gmean(df[\"S2\"])\n",
    "print(\"The geometric mean of column 'S2' is {} mg/dL\".format(df_s2_gmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also calculate the geometric mean for every column by the function provided by `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, gm in zip(df.columns, gmean(df)):\n",
    "    print(\"{} : {}\".format(col, gm))\n",
    "# gmean(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonic Mean\n",
    "Another kind of mean is harmonic mean that is also provided by `scipy` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import hmean\n",
    "df_s2_gmean = hmean(df[\"S2\"])\n",
    "print(\"The harmonic mean of column 'S2' is {} mg/dL\".format(df_s2_gmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also calculate the harmonic mean for every column by the function provided by `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, gm in zip(df.columns, hmean(df)):\n",
    "    print(\"{} : {}\".format(col, gm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median\n",
    "We can simply find the median of the data in a column by calling `median` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_median = df[\"S2\"].median()\n",
    "print(\"The median of column 'S2' is {} mg/dL\".format(df_s2_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the whole dataframe's median easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles\n",
    "Quantiles also can be calculated by method `quantile`. The quantile 0.5 is exactly the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(q=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can also call this method to calculate another quantiles like 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(q=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode\n",
    "To calculate the mode of each column you can use `mode` method like below. Note that there may be more than one modes in the data, because of equality betweeen their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S2'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course you can call `mode` method on the whole dataframe instead of just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimmed Mean\n",
    "Using scipy we can calculate trimmed mean for a column or even whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import trim_mean\n",
    "df_s2_tmean = trim_mean(df[\"S2\"], proportiontocut=0.15)\n",
    "print(\"Trimmed mean of S2 column with proportion cut of 15% is {}.\".format(df_s2_tmean))\n",
    "print(\"Trimmed mean for whole dataframe with proportion cut of 15% is as below: \")\n",
    "for col, mean in zip(df.columns, trim_mean(df, 0.15)):\n",
    "    print(\"{} : {}\".format(col, mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range\n",
    "Finding range in python. The difference between min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_range = df[\"S2\"].max() - df[\"S2\"].min()\n",
    "df_s2_range\n",
    "print(\"The range of column S2 is : {}.\".format(df_s2_range))\n",
    "\n",
    "print(\"And below is the range of whole dataframe: \")\n",
    "df.max() - df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Deviation\n",
    "The mean absolute deviation can be calculated by `mad` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2 = df[\"S2\"].copy()\n",
    "df_s2_mad = (df_s2 - df_s2.mean()).abs().mean()\n",
    "print(\"The mean absolute deviation of column S2 is: {}.\".format(df_s2_mad))\n",
    "print(\"And the mean absolute deviation of whole dataframe are as below: \")\n",
    "(df - df.mean()).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Standard Deviation\n",
    "Variance and Standard Deviation can be calculated by `var` and `std` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_var = df[\"S2\"].var()\n",
    "df_s2_std = df[\"S2\"].std()\n",
    "print(\"Variance of column S2 is {} and its standard deviation is {}.\".format(df_s2_var, df_s2_std))\n",
    "print(\"Variance of whole dataframe: \")\n",
    "print(df.var())\n",
    "print(\"Standard Deviation of whole dataframe: \")\n",
    "print(df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    return (data - data.mean()) / data.std()\n",
    "\n",
    "standardized_data_s2 = standardize_data(df['S2'])\n",
    "\n",
    "print(\"Here's standardized data in another dataframe.\")\n",
    "print(standardized_data_s2)\n",
    "\n",
    "print(\"The mean of standardized data is 0 and its variance is 1.\")\n",
    "print(\"Mean =\", round(standardized_data_s2.mean(), 4))\n",
    "print(\"Var =\", round(standardized_data_s2.var(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_cv = df[\"S2\"].std() / df[\"S2\"].mean()\n",
    "print(\"Coefficient of Variation of S2 is: {}.\".format(df_s2_cv))\n",
    "\n",
    "print(\"Coefficient of Variation of whole dataframe are as below: \")\n",
    "df.std() / df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarters' half range\n",
    "To calculate half range of some data we can calculate average of first and third quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_qhr = (df[\"S2\"].quantile(0.75) - df[\"S2\"].quantile(0.25)) / 2\n",
    "print(\"Quarters' half range of column S2 is\", df_s2_qhr)\n",
    "\n",
    "print(\"Quarters' half range of whole dataframe: \")\n",
    "(df.quantile(0.75) - df.quantile(0.25)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interquartile range\n",
    "Interquartile range is the first derivative of Quarters' half range. It is a kind of estimates of location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2_iqr = (df[\"S2\"].quantile(0.25) + df[\"S2\"].quantile(0.75)) / 2\n",
    "print(\"Interquartile range of column S2 is\", df_s2_iqr)\n",
    "\n",
    "print(\"Interquartile range of whole dataframe: \")\n",
    "(df.quantile(0.25) + df.quantile(0.75)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment\n",
    "To calculate the `r`th central moment you can run as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "r = 3\n",
    "moment(df[\"S2\"], r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"S6\"].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can calculate whole dataframe's skewness like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"S4\"].kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can calculate whole dataframe's kurtosis like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem and Leaf Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemgraphic.stem_graphic(df[\"S2\"], scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "x_axis = np.arange(-20, 20, 0.01)\n",
    "mean = x_axis.mean()\n",
    "std = x_axis.std()\n",
    "plt.plot(x_axis, norm.pdf(x_axis, mean, std))\n",
    "plt.show()\n",
    "plt.boxplot(x_axis, vert=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
